{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "from collections import Counter\n",
    "import collections\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('/home/waqas/avrios/mapping-pass.lst', header=None, index_col=None)\n",
    "frame.columns = ['uuids']\n",
    "frame['uuids'] = frame['uuids'].str.replace('annotated_page.xml', 'original.pdf')\n",
    "frame['uuids'] = frame['uuids'].str.strip('./')\n",
    "name = '/home/waqas/avrios/'\n",
    "frame = name + frame\n",
    "frame.to_csv('pdfs_to_be_uploaded.txt', index=False, header=None)\n",
    "\n",
    "\n",
    "# annotated_xmlList = glob.glob('/home/waqas/Videos/test/*/annotated_page*.xml')\n",
    "# pdf_files = glob.glob('/home/waqas/Videos/*/*/*.pdf')\n",
    "\n",
    "# for xml in annotated_xmlList:\n",
    "#     splitRes = xml.split('/')\n",
    "#     xmlFolder = xml.replace(splitRes[len(splitRes) -1], \"\")\n",
    "#     with open(xml) as xmlFile:\n",
    "#         doc = xmltodict.parse(xmlFile.read())\n",
    "#         page = doc['PcGts']['Page'] \n",
    "        \n",
    "#         for pdf in pdf_files:\n",
    "#             if 'ImageRegion' in page:         \n",
    "#                 shutil.copy2(pdf, '/home/waqas/Videos/test/')\n",
    "#             else:\n",
    "#                 shutil.copy2(xml, '/home/waqas/Videos/test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To copy files with same names in different directories\n",
    "\n",
    "output_dir = \"/home/waqas/deleted3/\"\n",
    "\n",
    "with open('/home/waqas/avrios/pdfs_to_be_uploaded.txt', 'r') as filelist:\n",
    "    for filepath in filelist:\n",
    "        uuid_folder = filepath.split('/')[-2]\n",
    "        new_path_folder = os.path.join(output_dir, uuid_folder)\n",
    "        os.makedirs(new_path_folder)        \n",
    "        shutil.copy2(filepath.strip(), new_path_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/home/waqas/Desktop/csvmerge/service/*/*/*.csv')\n",
    "xmlList = glob.glob('/home/waqas/avrios1/avrios/*/*page.xml')\n",
    "# result -> [./avrios/0af37316-b4fd-498a-ba57-8082f82ac9e1/page.xml', ./avrios/0af37316-b4fd-498a-ba57-...', ...]\n",
    "\n",
    "\n",
    "for xml in xmlList:\n",
    "    splitRes = xml.split(\"/\")\n",
    "    xmlFolder = xml.replace(splitRes[len(splitRes) - 1], \"\")\n",
    "    # result e.g. -> ./avrios/0af37316-b4fd-498a-ba57-8082f82ac9e1/',\n",
    "    \n",
    "    with open(xml) as xmlFile:\n",
    "        doc = xmltodict.parse(xmlFile.read())\n",
    "        pdf_name = doc['PcGts']['Property'][3]['@value']\n",
    "\n",
    "        csv_name = pdf_name.replace('.pdf', '*.csv')\n",
    "        csvFiles = glob.glob('/home/waqas/Desktop/csvmerge/service/*/*/*' + csv_name)\n",
    "        \n",
    "        for csvfile in csvFiles:\n",
    "            shutil.copy2(csvfile, xmlFolder)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         # find pdf name in xml\n",
    "#         doc = xmltodict.parse(xmlFile.read())\n",
    "#         page = doc['PcGts']['Property'][3]\n",
    "#         convert_to_dict =  collections.OrderedDict(page)\n",
    "#         pdfName = convert_to_dict['@value']\n",
    "        \n",
    "#         # replace pdf name with \"PDF_PREFIX*.csv\" \n",
    "#         csvName = pdfName.replace(\".pdf\", \"*.csv\")\n",
    "        \n",
    "#         # find/browse all respective csvs\n",
    "#         csvFiles = glob.glob('/home/waqas/Desktop/csvmerge/service/*/*/*' + csvName)\n",
    "        \n",
    "#         # resturns a list of all respective csvs\n",
    "#         # e.g. ['./csvs/20180731/2627cf00-dad6-4209-9562-f28913d71acb/RE_HHS7572-1-2_vehicle.csv', './csvs/20180731/2627cf00-dad6-4209-9562-f28913d71acb/RE_HHS7572-1-2_line_items.csv', './csvs/20180731/2627cf00-dad6-4209-9562-f28913d71acb/RE_HHS7572-1-2_invoice_header.csv']\n",
    "#         for csvFile in csvFiles:\n",
    "#             print(type(csvFile))\n",
    "# #             shutil.copy2(csvFile, xmlFolder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with uuids and filenames for both folders csvmerge and damage folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".maskenv",
   "language": "python",
   "name": ".maskenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
