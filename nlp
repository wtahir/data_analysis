https://vie001.internal.omnius.com/engine/api/v2/collections/f974e70c-d03a-486a-b121-87fc1b5383db/documents/fdc579b7-a704-4635-bb54-4a07e4936c83/

https://vie001.internal.omnius.com/engine/api/v2/collections/f974e70c-d03a-486a-b121-87fc1b5383db/documents/fdc579b7-a704-4635-bb54-4a07e4936c83/data

https://vie001.internal.omnius.com/engine/api/v2/collections/f974e70c-d03a-486a-b121-87fc1b5383db/documents/fdc579b7-a704-4635-bb54-4a07e4936c83/files

https://vie001.internal.omnius.com/engine/api/v2/collections/f974e70c-d03a-486a-b121-87fc1b5383db/documents/fdc579b7-a704-4635-bb54-4a07e4936c83/files/validated-page.xml


https://platform-cck-2.internal.omnius.com/engine/api/v2/collections/a0ca474e-3cce-44bd-92b2-3d3a757ec045/documents/b8d50e82-7c1c-49be-a34b-436d5a40a04b/files/validated-page.xml




# to open sftp files and cp to local/ chanage files
kubectl exec platform-cck-2-qa-omnius-api-c587694f4-htrll -it -n engine -- bash


# link to airflow
https://platform-cck-2.internal.omnius.com/engine/airflow/admin/airflow/tree?dag_id=engine-dynamic&num_runs=&root=


# watching training logs
- kubectl get pods -n trainer
- open training and copy the running pod link
- kubectl logs -f -n trainer {pod link}


# connect to dbeaver
kubectl get pods -n trainer | grep postgres
kubectl port-forward platform-cck-2-qa-postgres-omnius-78c78f74d7-sslrl 5441:5432 -n trainer


# to remove ./ from file list
sed 's|^./||' filename.lst


# find a directory via terminal
find . -type d | grep DIRNAME


# get model tags in json via URL
https://platform-cck-2.internal.omnius.com/trainer/api/v2/trainer/data-models/


# resume a screen
screen -r


# detach a screen
ctrl + a d


# see list of screens
screen -ls


# kill a screen 
screen -X -S [session # you want to kill] quit


# sort in bash (2nd column, then 1st column of the file pepole.txt)
sort -k2,2 -k1,1 <people.txt


# train question answering with xmls
question_answering_train_xml.py --train_data_path trainNotNan.lst --val_data_path valNotNan.lst --train.mlflow.tracking_uri ../output --train.dataset.doc_id basename --train.dataset.sample_selector //_:PcGts --test_data_path testNotNan.lst --train.trainer.gpus 1


# create mlevaluation report
mleval_entity_recognition_report.py /home/waqas/repos/platform-client/platform_client/invoice_gt/invoice_gt.conll /home/waqas/repos/platform-client/platform_client/invoice_pr/invoice_pr.conll /home/waqas/Downloads/train_tags.txt report_invoice

# convert to conll, list files are the list of xmls
pagexml_to_conll_2003.py invoice_pr.lst invoice_pr.conll
 


# train question answering
question_answering_train_csv.py --train_data_path question_answering_tests/data/train.csv --val_data_path question_answering_tests/data/val.csv --train.dataset.column.text description   --train.dataset.column.doc_id file --train.dataset.column.questions question_1 question_2 question_3   --train.dataset.sep , --train.mlflow.tracking_uri test-training-csv/ --train.trainer.gpus 1

# to execute an image called compassionate_gates in bash
docker exec -it compassionate_gates bash

# run a docker container with name "packages-qa.omnius.com/omnius/question-answering:0.2.1", -p to specify port (local:remote check this one), -dit detchable, --entrypoint which is bash, -v (volume) #to mount a folder in the docker container PATH_TO_FOLDER:DESTINY_FOLDER_NAME
docker run -p 5000:5000 -dit --entrypoint bash -v /home/waqas/repos/question_answering:/waqas_data/  packages-qa.omnius.com/omnius/question-answering:0.2.1

# to run training using gpu in docker
nvidia-docker run --entrypoint bash -v /home/waqas/repos/question_answering:/waqasData/ -dit packages-qa.omnius.com/omnius/question-answering:0.2.1

# Install nvidia drivers for docker container
https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker


# run platform-client to download collection xmls
python platform_client/export.py export_collection 818fe13d-9822-4fd1-b296-819303085040 rejected_nicht_versichertes_objekt https://vie001.internal.omnius.com/engine https://vie001.internal.omnius.com/shield steinfeld@omnius.com Steinfeld_123 v2


# mounting external directory (e.g. mount to BAS and mount on folder mnt)
sudo mount -t cifs -o username=waqas,sec=ntlm,vers=1.0 //172.23.0.201/BAS ~/mnt


# copying a docker container to remote with progress bar
rsync -azP /home/waqas/LOB/qa.tar  waqas@172.23.0.186:/home/waqas/question_answering


# upload collection:
python client_v2_1.py --config ../platform.yaml upload_dir --collection_id bb826877-3ff8-482d-8528-b3f81849cd86 --in_dir /home/waqas/Desktop/upload_BAS_corrected/ --pipeline_queue_name trainer-dynamic --priority true


# unmount
mount -l ~/mnt


# remove double quotes from each line:
cat damage_upload.lst | sed 's/"//g' > filename.lst

# common files between two files list
comm -12 <(sort set1.txt) <(sort set2.txt)


# uncommon files between two file lists
comm -3 <(sort base_engine.lst) <(sort risks.lst)


# remove '.pdf' from the centre of the filename
for file in *; do mv "${file}" "${file/.pdf/}"; done


# opening pdfs with name and trigger new open after cancelling:
for p in *.pdf; do echo $p; evince $p; read; done


# Use of jq to get list of files from cck:
python platform_client/client_v2.py --config engine.yaml get_documents --collection_id 63dcff7a-8bf9-4ed5-b3ac-e6801a3d7694 | jq '.payload.items[].file_name'


# get data model json:
python client_v2_1.py --config ../trainer.yaml get_data_model --data_model_id 68f51c14-828d-48e8-a5c3-ca7a55d25c32 | jq '.payload'


# see the list of files which are not present (it needs sorted list of both files):
comm 1st.lst 2nd.lst -3


# word count:
wc -l <filename>


# open list of pdfs:
while read p; do evince "$p"; done <filtered_list.lst


# creating list of files:
find /home/waqas/data/proof_cancellation/ -name "origin.pdf" | sort > pdfs.txt


# list, print and count unique
ls *.pdf | awk -F _ '{print $1}' | sort | uniq -c | wc -l


# copying files based on list as a text file:
while read file; do cp "$file" folder_to_be_copied_to; done < filelist.lst


# adding file extention:
for f in *; do mv "$f" "$(printf "$f.png")"; done


# renaming with padding added:
for f in *.png; do mv "$f" "$(printf "%03i%s" "$f")"; done


#renaming files
ls -v | cat -n | while read n f; do mv -n "$f" "$n.png"; done


# renaming files with padding
n=1; for f in *.txt; do mv "$f" "$(printf "CO_%02i_%s" "$n" "$f")"; ((n++)); done


# replacing filenames globally and saving it in a list
cat class15_filtered_100.lst | sed 's|.tif|_ocr.xml|g' > class15_filtered_100a.lst


# remove a file recursively from subdirs
find . -type f -name '*.o' -delete


# remove all files except '*.any'
find . -type f ! -name '*.any' -delete 


# to delete files that are not in .lst
ls | grep -v -F -f <(cat ../class*lst | sed 's|.*/||' | sort -u) | xargs mv -t ../data_TRASH/


# to cp files through a list to a folder
xargs -a class4_filtered_100a.lst cp -t tocopy/



# docker-command-line will create issues, add it to path:
export PATH="$PATH:/home/waqas/projects/docker-command-line-interface"


# to change the ocred xmls into required lists:
sed 's/origin_page.xml/page.xml/' ocrs.txt > gts.txt

# renaming files using bash
for filename in IMG-*; do echo mv \"$filename\" \"${filename//IMG-/}\"; done | bash


# to replace to absolute path:
sed -i 's/\./\/home\/waqas\/data\/azp/' merged.txt


# useful for checking lines in code:
wc -l merged.txt


# renaming files start from 1:
a=1
for i in *.jpg; do
  new=$(printf "%d.png" "$a") #04 pad to length of 4
  mv -i -- "$i" "$new"
  let a=a+1
done


# error for levenstein distance
error: command 'x86_64-linux-gnu-gcc' failed with exit status 1
 or pyhthon - levenstein problem:
sol:
sudo apt-get install python3 python-dev python3-dev \
     build-essential libssl-dev libffi-dev \
     libxml2-dev libxslt1-dev zlib1g-dev \
     python-pip


# grep word tag from xmls and no idea what sort does:
find . -iname merged.xml | xargs -I XXX grep -H -c '</Word>' XXX | sort -n -k2 -t:


# Setup the pypi server, look in lastpass pip.conf.
Install mlevaluation. 
mleval_text_recognition_report.py --help


# To create page-xml from images:
pagexml_create.py -o Schadenbild3986600565622701331.xml Schadenbild3986600565622701331.jpg


# md5sum
find -iname *.pdf | xargs md5sum > ../service1.md5


# copy from one place to another
cat contains_matching_ids.txt | awk -F"\t" '{print $2" "$3}' | sed 's|/home/waqas/avrios/||g' | sed 's|/original.pdf||g' | awk '{printf("cp /home/waqas/avrios/"$1"/merged.xml /home/waqas/avrios1/avrios/"$2"/merged.xml\n")}' | bash


# replace same filenames in directories
for subdir in *; do mv $subdir/page.xml $subdir/empty.xml; done;
